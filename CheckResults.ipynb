{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PREFIX='a video of '\n",
    "events = [\n",
    "        \"Riding\",\n",
    "        \"Fighting\",\n",
    "        \"Playing\",\n",
    "        \"Running\",\n",
    "        'Lying',\n",
    "        \"Chasing\",\n",
    "        \"Jumping\",\n",
    "        \"Falling\",\n",
    "        \"Guiding\",\n",
    "        \"Stealing\",\n",
    "        \"Littering\",\n",
    "        \"Tripping\",\n",
    "        \"Pickpockering\",\n",
    "    ]\n",
    "description = [\n",
    "        \"a person riding a bicycle on the street\",  # Added context\n",
    "        \"multiple people engaged in a physical fight\",  # More specific than \"fighting\"\n",
    "        \"a group of people playing a sport together\",  # Added \"sport\" for visual clarity\n",
    "        \"a person running\",  # Added context\n",
    "        \"a person lying motionless on the ground\",  # \"Motionless\" helps distinguish from falling\n",
    "        \"a person aggressively chasing another person\",  # \"Aggressively\" adds distinction\n",
    "        \"a person jumping high in the air with both feet\",  # More specific than just \"jumping\"\n",
    "        \"a person accidentally falling to the ground\",  # \"Accidentally\" helps distinguish\n",
    "        \"a person gently guiding another person by the arm\",  # Added detail\n",
    "        \"a person stealing other person\",  # More specific than \"stealing\"\n",
    "        \"a person deliberately throwing garbage on the ground\",  # \"Deliberately\" adds clarity\n",
    "        \"a person tripping over an obstacle\",  # More descriptive\n",
    "        \"a person pickpocketing a wallet from someone's pocket\",  # Very specific\n",
    "    ]\n",
    "description=[PREFIX+desc for desc in description]\n",
    "events_description = {event: desc for event, desc in zip(events, description)}\n",
    "normal_class = PREFIX + \"a normal view (persons walking or standing)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[295 300 305 310 315 320 325 330 335 340 345 350 355 360 365 370 375 380\n",
      " 385 390 395 400 405 410 415 420 425 430 435 440 445 450 470 475] ['a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'\n",
      " 'a video of a normal view (persons walking or standing)'] ['' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '']\n"
     ]
    }
   ],
   "source": [
    "rute='/home/ubuntu/Tesis/Storage/CLIPOneCLass'\n",
    "info_stored=np.load(f\"{rute}/000350_CLIP_2_a video of a person riding a bicycle on the street.npy\", allow_pickle=True)\n",
    "frames_number=info_stored[0]\n",
    "predicted_events=info_stored[1]\n",
    "prompts=info_stored[2]\n",
    "print(frames_number, predicted_events, prompts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
